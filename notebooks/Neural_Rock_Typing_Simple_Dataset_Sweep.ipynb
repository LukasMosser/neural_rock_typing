{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qcFFZDhDCy3E",
   "metadata": {
    "id": "qcFFZDhDCy3E"
   },
   "source": [
    "## Neural Rock Train Model Notebook\n",
    "\n",
    "The following cell sets up the entire repository from githubg and links to the google drive where the dataset it stored. After all the requirements get installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "institutional-attribute",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "institutional-attribute",
    "outputId": "9e1a5ee2-e904-40cd-f077-100f124b4688"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    import os\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "\n",
    "    user = input('User name: ')\n",
    "    password = getpass('Password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "\n",
    "    cmd_string = 'git clone https://{0}:{1}@github.com/LukasMosser/neural_rock_typing.git'.format(user, password)\n",
    "\n",
    "    os.system(cmd_string)\n",
    "    cmd_string, password = \"\", \"\" # removing the password from the variable\n",
    "    os.chdir(\"./neural_rock_typing\")\n",
    "    os.system('pip install -r requirements.txt')\n",
    "    os.system('pip install -e .')\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xO2loavbW0WL",
   "metadata": {
    "id": "xO2loavbW0WL"
   },
   "source": [
    "### A Hack needed to make Pytorch Lightning work with Colab again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91wcJjWX6cm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91wcJjWX6cm8",
    "outputId": "a3c4f7e7-bc67-4214-aa35-fc4ff1d8d79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (0.10.27)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/lmoss/.local/lib/python3.7/site-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (3.15.8)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click>=7.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: pathtools in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: PyYAML in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/lmoss/.local/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/lmoss/.local/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
      "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-2shk7l4f\n",
      "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-2shk7l4f\n",
      "  Running command git submodule update --init --recursive -q\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64eb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3sW6uB2zCxoq",
   "metadata": {
    "id": "3sW6uB2zCxoq"
   },
   "source": [
    "## Login to Weights & Biases for Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "iA58DQTTmfbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA58DQTTmfbc",
    "outputId": "deb72664-9082-45c4-8ee2-99434fe236c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-mosser\u001b[0m (use `wandb login --relogin` to force relogin)\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-monitoring",
   "metadata": {
    "id": "second-monitoring"
   },
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpine-hanging",
   "metadata": {
    "id": "alpine-hanging"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from neural_rock.dataset import SimpleThinSectionDataset\n",
    "from neural_rock.model import NeuralRockModel, make_vgg11_model, make_resnet18_model\n",
    "from neural_rock.plot import visualize_batch\n",
    "from neural_rock.utils import MEAN_TRAIN, STD_TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-impression",
   "metadata": {
    "id": "occasional-impression"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "NX_8WWBgPjO5",
   "metadata": {
    "id": "NX_8WWBgPjO5"
   },
   "outputs": [],
   "source": [
    "wandb_name = 'lukas-mosser'\n",
    "project_name = 'neural_rock_simple'\n",
    "\n",
    "labelset = \"Lucia_class\"\n",
    "dataset_fname = \"Leg194_dataset.csv\"\n",
    "learning_rate = 3e-4\n",
    "batch_size = 16\n",
    "weight_decay = 1e-5\n",
    "dropout = 0.5\n",
    "\n",
    "model = 'vgg'\n",
    "frozen = True\n",
    "    \n",
    "train_dataset_mult = 50\n",
    "val_dataset_mult = 50\n",
    "\n",
    "seed_dataset = 42\n",
    "\n",
    "base_path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b2260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmoss/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed_dataset)\n",
    "\n",
    "df = pd.read_csv(base_path+\"/\"+dataset_fname)\n",
    "df.head()\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "valid_rows = df[df[labelset].notnull() & df[\"Xppl\"].notnull()]\n",
    "\n",
    "valid_rows[\"y\"] = label_encoder.fit_transform(valid_rows[labelset])\n",
    "\n",
    "index = valid_rows.index\n",
    "\n",
    "train_index, test_index = train_test_split(index, test_size=0.5, stratify=valid_rows[\"y\"])\n",
    "\n",
    "df_train = valid_rows.loc[train_index].reset_index()\n",
    "df_val = valid_rows.loc[test_index].reset_index()\n",
    "\n",
    "print(len(df_train), len(df_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fqZTGkOCtAV",
   "metadata": {
    "id": "9fqZTGkOCtAV"
   },
   "source": [
    "## Perform Training Sweep across 12 Models\n",
    "\n",
    "We train a Resnet and a VGG network each with a frozen feature extractor for each labelset: Lucia, Dunham, and DominantPore Type. \n",
    "\n",
    "This leads to a total of 12 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767b28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation used for Training\n",
    "data_transforms = {\n",
    "  'train': transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(degrees=360),\n",
    "      transforms.RandomCrop((512, 512)),\n",
    "      transforms.ColorJitter(hue=0.5),\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "  ]),\n",
    "  'val':\n",
    "      transforms.Compose([\n",
    "          transforms.RandomCrop((512, 512)),\n",
    "          transforms.Resize((224, 224)),\n",
    "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "      ])\n",
    "}\n",
    "\n",
    "# Load the Datasets\n",
    "train_dataset_base = SimpleThinSectionDataset(base_path, df_train, transform=data_transforms['train'])\n",
    "\n",
    "val_dataset_base = SimpleThinSectionDataset(base_path, df_val, transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1160e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataloaders\n",
    "train_loader = DataLoader(train_dataset_base, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader = DataLoader(val_dataset_base, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0C6Tp6_ag5sq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "0C6Tp6_ag5sq",
    "outputId": "d0c52c66-29f6-440f-d4bb-5b2904c36feb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | feature_extractor | Sequential | 9.2 M \n",
      "1 | classifier        | Sequential | 6.4 M \n",
      "2 | train_f1          | F1         | 0     \n",
      "3 | val_f1            | F1         | 0     \n",
      "-------------------------------------------------\n",
      "6.4 M     Trainable params\n",
      "9.2 M     Non-trainable params\n",
      "15.7 M    Total params\n",
      "62.614    Total estimated model params size (MB)\n",
      "/home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3810274351074f039d9b3db74e3842cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba67084baa746c3a7be507a647b9516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmoss/.conda/envs/neural_rock/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 23, global step 68: val/f1 reached 0.00000 (best 0.00000), saving model to \"/home/lmoss/neural_rock_typing/notebooks/data/models/Lucia_class/vgg/True/best-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31662<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/lmoss/neural_rock_typing/notebooks/wandb/run-20211128_182649-3ou0glcf/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/lmoss/neural_rock_typing/notebooks/wandb/run-20211128_182649-3ou0glcf/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.739</td></tr><tr><td>train/f1</td><td>0.63043</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>trainer/global_step</td><td>68</td></tr><tr><td>_runtime</td><td>1364</td></tr><tr><td>_timestamp</td><td>1638121773</td></tr><tr><td>_step</td><td>22</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▃▂▂▂▁▂▁▂▂▂▂▁▂▂▁▂▁▁▁▃▂▂</td></tr><tr><td>train/f1</td><td>▁▅▆▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lukas-mosser</strong>: <a href=\"https://wandb.ai/ccg/neural_rock_simple/runs/3ou0glcf\" target=\"_blank\">https://wandb.ai/ccg/neural_rock_simple/runs/3ou0glcf</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lukas-mosser</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ccg/neural_rock_simple\" target=\"_blank\">https://wandb.ai/ccg/neural_rock_simple</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ccg/neural_rock_simple/runs/v4d0x313\" target=\"_blank\">https://wandb.ai/ccg/neural_rock_simple/runs/v4d0x313</a><br/>\n",
       "                Run data is saved locally in <code>/home/lmoss/neural_rock_typing/notebooks/wandb/run-20211128_184953-v4d0x313</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | feature_extractor | Sequential | 9.2 M \n",
      "1 | classifier        | Sequential | 6.4 M \n",
      "2 | train_f1          | F1         | 0     \n",
      "3 | val_f1            | F1         | 0     \n",
      "-------------------------------------------------\n",
      "6.4 M     Trainable params\n",
      "9.2 M     Non-trainable params\n",
      "15.7 M    Total params\n",
      "62.614    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b306b9853624491db772b80f78158411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace2911f56dd4733a171d042a9628008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in range(10):\n",
    "    # Set the base path for the models to be stored in the Google Drive\n",
    "    path = Path(\"./data/models/{0:}/{1:}/{2:}\".format(labelset, model, str(frozen)))\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Set the Random Seed on Everything\n",
    "    pl.seed_everything(seed)\n",
    "\n",
    "\n",
    "    # Setup Weights and Biases Logger\n",
    "    wandb_logger = WandbLogger(name=wandb_name, project='neural_rock_simple', entity='ccg')\n",
    "    wandb_logger.experiment.config.update({\"labelset\": labelset, \"model\": model, 'frozen': str(frozen)})\n",
    "    tensorboard_logger = TensorBoardLogger(\"lightning_logs\", name=labelset)\n",
    "\n",
    "    # Checkpoint based on validation F1 score\n",
    "    checkpointer = ModelCheckpoint(dirpath=path, filename='best', monitor=\"val/f1\", verbose=True, mode=\"max\")\n",
    "\n",
    "    # Setup the Pytorch Lightning Dataloader\n",
    "    trainer = pl.Trainer(gpus=-1, \n",
    "                       max_steps=15000, \n",
    "                       benchmark=True,\n",
    "                      logger=[wandb_logger, tensorboard_logger],\n",
    "                      callbacks=[checkpointer],\n",
    "                      progress_bar_refresh_rate=20,\n",
    "                      check_val_every_n_epoch=1)\n",
    "\n",
    "    # Select which model to run\n",
    "    if model == 'vgg':\n",
    "        feature_extractor, classifier = make_vgg11_model(train_dataset_base.num_classes, dropout=dropout)\n",
    "    elif model == 'resnet':\n",
    "        feature_extractor, classifier = make_resnet18_model(train_dataset_base.num_classes)\n",
    "\n",
    "    # Create the model itself, ready for training\n",
    "    model_ = NeuralRockModel(feature_extractor,\n",
    "                           classifier, \n",
    "                           num_classes=train_dataset_base.num_classes, \n",
    "                           freeze_feature_extractor=frozen)\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model_, train_dataloader=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "    # Clean up Weights and Biases Logging\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wBdnzL60VLzp",
   "metadata": {
    "id": "wBdnzL60VLzp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sweep Neural Rock Typing - Train Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
